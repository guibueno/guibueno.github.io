---
title: User Tests
layout: doc
section: eval
incomplete: no
---

The *self-assessment video* feature works on the assumption that if language learners are given the chance to take risks and to even make mistakes, their practice time will become more effective. Therefore, rather than constantly letting learners know if their speech is right or wrong, **LanguageBug** would prompt them to record a video of themselves after each practice.

Learners would then be able to evaluate their own learning progress and assess their own language proficiency. The purpose of conducting user tests was to collect initial feedback on this feature and to generate more design questions. 

### Primary goal

My peers and instructor made me aware of other hypotheses and some concerns related with the *self-assessment video feature*, such as:

- Would this kind of video really be motivating to learners?
- Could these videos make learners feel shy and embarassed?
- Would learners be interested in watching themselves speaking?

The primary goal of the user tests was to collect initial information that could guide me on verifying these hypotheses.

### Secondary goals

Conduct user tests would also provide me with general insights on usability, such as:

- evaluate if the mechanics of the application are working well, 
- if the features are easy to access and user friendly,  
- understand how users feel while using the app,
- discover additional gaps I would like to address, and
- find out other perceptions and reflections on the app.

### Research method

I performed a "*Wizard of OZ*" simulation of the **LanguageBug** application. According to the Handbook of human-computer interaction (Helander, 2014),

> "The ability to simulate the eventual interface on the basis of early designs is a real advantage. One technique that is used is referred to as the 'Wizard of Oz' method. In this, the interface is simulated with the aid of human confederates. This is particularly useful in cases where a complex task machine would have to be built in order to test an actual implementation of the design" (p. 987)

My roles as the "Wizard of Oz" were:

- to walk users through the different simulated app screens,
- to speak Portuguese at all times an audio would be played,
- to give command prompts to the users on a established order,
- to praise efforte and encourage learners to keep trying, and
- to record the learners performance after each practice.

During the whole test, I observed users reactions, but refraining myself from:

- providing additional information on the prompts,
- explaining the sentences beyond their translation, and
- making any sort of correction or interference.

After the tests, I conducted a brief one-on-one interview with each participant, in which I asked open questions such as:

- how are you feeling?
- how did you like this experience?
- do you have any feedback or concern you want to share?
- would you try and learn a language in this way?

After the tests, I sent the (supposedly) **self-assessment videos** to each of the users with a post-test questionnaire to assess:

- how much learning they believe they have accomplished,
- how they felt when they saw themselves speaking Portuguese,
- how they would assess their own performance, and
- if they would expect their performance to be better after a second practice.

### Recruitment strategy 

Since **LanguageBug** targets adults learners who do not speak Portuguese, there were many eligible user testers in the DMDL/G4L programs. I selected user testers based on responses on a quick online [survey](https://docs.google.com/forms/d/12VRYNiSausPkOfFtaqPWu12kPYB-qwK0PhMY_1JBxTU/edit?usp=sharing_eid&ts=57116ed1), which assessed:

- prior experience with or exposure to the Portuguese languge,
- interest in learning Portuguese, and
- self-beliefs on language learning abilities.

The complete rationale for this pre-questionnaire survey can be found in the Appendixes.

### Location

The user tests were conducted at NYU MAGNET.

### Materials

A low-fidelity prototype built on Google Slides was used during the user tests. The slides provided users with the actual content from **LanguageBug: Portuguese**.

![Landscape Audit](/images/eval-plan-prototype.png)
{: style="text-align: center"}
**Image** - _Screen-shot of the material used on the user tests_
{: style="text-align: center"}
ADD

Results to Pre-questionnaire
Consequences to each evaluation section
UX workshop: reveal.js, fast-pace, orders
Individual project focus: question from meeting with adviser
Nicole: wizard of OZ, resultado, goals, improvement, OPI, RESPONSIVENESS (question from Individual project focus)
User tests

	User tests:

	Evaluate

	if users respond to prompts
	if usability is fine
	if method works

	Nicole: example of speech
	method test: wizard of OZ prototype
	feedback on method: performance assessment
	user observation: in a wizard of O?
	interview?: it didn't happen
	Nissa: what should I do?

Post-questionnaire (or maybe information on interview?)
Overall consequences: stay with self-evaluation


CONSIDER

RATIONALE ==> FAQ ==> Evaluation

EVALUATION: methods used to iterate/evaluate and the results


NICOLE'S SPEECH IN THE DESIGN RATIONALE?

FAQ: why no corrections?
Nicole after 2 sessions
Focus on quantity, rather than quality
Repetition






SHASHANK: mark all sections that could probably use some referencing, then find references



USER OBSERVATION: hands on the table. Nice to have more reinforcement on performance/trying!




In order to assess learnersâ€™ reactions or attitudes toward the

learning experience, it is usually best to use a mixture of open-ended questions and closed-

ended questions, according to Reiser and Dempsey (2011, p.99 ).



Review - after
Constant feel of challenge could be stressful
Independently of doing it again tomorrow, it'd be nice to review immediately after the exercise